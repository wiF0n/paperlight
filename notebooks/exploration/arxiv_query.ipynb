{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the default API client.\n",
    "client = arxiv.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query = \"document question answering AI\",\n",
    "  max_results = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.results(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document AI: Benchmarks, Models and Applications\n",
      "\n",
      "['cs.CL']\n",
      "Document AI, or Document Intelligence, is a relatively new research topic\n",
      "that refers to the techniques for automatically reading, understanding, and\n",
      "analyzing business documents. It is an important research direction for natural\n",
      "language processing and computer vision. In recent years, the popularity of\n",
      "deep learning technology has greatly advanced the development of Document AI,\n",
      "such as document layout analysis, visual information extraction, document\n",
      "visual question answering, document image classification, etc. This paper\n",
      "briefly reviews some of the representative models, tasks, and benchmark\n",
      "datasets. Furthermore, we also introduce early-stage heuristic rule-based\n",
      "document analysis, statistical machine learning algorithms, and deep learning\n",
      "approaches especially pre-training methods. Finally, we look into future\n",
      "directions for Document AI research.\n",
      "________________________________________________________________________________\n",
      "LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking\n",
      "\n",
      "['cs.CL', 'cs.CV']\n",
      "Self-supervised pre-training techniques have achieved remarkable progress in\n",
      "Document AI. Most multimodal pre-trained models use a masked language modeling\n",
      "objective to learn bidirectional representations on the text modality, but they\n",
      "differ in pre-training objectives for the image modality. This discrepancy adds\n",
      "difficulty to multimodal representation learning. In this paper, we propose\n",
      "\\textbf{LayoutLMv3} to pre-train multimodal Transformers for Document AI with\n",
      "unified text and image masking. Additionally, LayoutLMv3 is pre-trained with a\n",
      "word-patch alignment objective to learn cross-modal alignment by predicting\n",
      "whether the corresponding image patch of a text word is masked. The simple\n",
      "unified architecture and training objectives make LayoutLMv3 a general-purpose\n",
      "pre-trained model for both text-centric and image-centric Document AI tasks.\n",
      "Experimental results show that LayoutLMv3 achieves state-of-the-art performance\n",
      "not only in text-centric tasks, including form understanding, receipt\n",
      "understanding, and document visual question answering, but also in\n",
      "image-centric tasks such as document image classification and document layout\n",
      "analysis. The code and models are publicly available at\n",
      "\\url{https://aka.ms/layoutlmv3}.\n",
      "________________________________________________________________________________\n",
      "Document-editing Assistants and Model-based Reinforcement Learning as a Path to Conversational AI\n",
      "\n",
      "['cs.AI', 'cs.HC', 'cs.LG']\n",
      "Intelligent assistants that follow commands or answer simple questions, such\n",
      "as Siri and Google search, are among the most economically important\n",
      "applications of AI. Future conversational AI assistants promise even greater\n",
      "capabilities and a better user experience through a deeper understanding of the\n",
      "domain, the user, or the user's purposes. But what domain and what methods are\n",
      "best suited to researching and realizing this promise? In this article we argue\n",
      "for the domain of voice document editing and for the methods of model-based\n",
      "reinforcement learning. The primary advantages of voice document editing are\n",
      "that the domain is tightly scoped and that it provides something for the\n",
      "conversation to be about (the document) that is delimited and fully accessible\n",
      "to the intelligent assistant. The advantages of reinforcement learning in\n",
      "general are that its methods are designed to learn from interaction without\n",
      "explicit instruction and that it formalizes the purposes of the assistant.\n",
      "Model-based reinforcement learning is needed in order to genuinely understand\n",
      "the domain of discourse and thereby work efficiently with the user to achieve\n",
      "their goals. Together, voice document editing and model-based reinforcement\n",
      "learning comprise a promising research direction for achieving conversational\n",
      "AI.\n",
      "________________________________________________________________________________\n",
      "Knowledge-Aided Open-Domain Question Answering\n",
      "\n",
      "['cs.CL']\n",
      "Open-domain question answering (QA) aims to find the answer to a question\n",
      "from a large collection of documents.Though many models for single-document\n",
      "machine comprehension have achieved strong performance, there is still much\n",
      "room for improving open-domain QA systems since document retrieval and answer\n",
      "reranking are still unsatisfactory. Golden documents that contain the correct\n",
      "answers may not be correctly scored by the retrieval component, and the correct\n",
      "answers that have been extracted may be wrongly ranked after other candidate\n",
      "answers by the reranking component. One of the reasons is derived from the\n",
      "independent principle in which each candidate document (or answer) is scored\n",
      "independently without considering its relationship to other documents (or\n",
      "answers). In this work, we propose a knowledge-aided open-domain QA (KAQA)\n",
      "method which targets at improving relevant document retrieval and candidate\n",
      "answer reranking by considering the relationship between a question and the\n",
      "documents (termed as question-document graph), and the relationship between\n",
      "candidate documents (termed as document-document graph). The graphs are built\n",
      "using knowledge triples from external knowledge resources. During document\n",
      "retrieval, a candidate document is scored by considering its relationship to\n",
      "the question and other documents. During answer reranking, a candidate answer\n",
      "is reranked using not only its own context but also the clues from other\n",
      "documents. The experimental results show that our proposed method improves\n",
      "document retrieval and answer reranking, and thereby enhances the overall\n",
      "performance of open-domain question answering.\n",
      "________________________________________________________________________________\n",
      "Visconde: Multi-document QA with GPT-3 and Neural Reranking\n",
      "\n",
      "['cs.CL', 'cs.IR']\n",
      "This paper proposes a question-answering system that can answer questions\n",
      "whose supporting evidence is spread over multiple (potentially long) documents.\n",
      "The system, called Visconde, uses a three-step pipeline to perform the task:\n",
      "decompose, retrieve, and aggregate. The first step decomposes the question into\n",
      "simpler questions using a few-shot large language model (LLM). Then, a\n",
      "state-of-the-art search engine is used to retrieve candidate passages from a\n",
      "large collection for each decomposed question. In the final step, we use the\n",
      "LLM in a few-shot setting to aggregate the contents of the passages into the\n",
      "final answer. The system is evaluated on three datasets: IIRC, Qasper, and\n",
      "StrategyQA. Results suggest that current retrievers are the main bottleneck and\n",
      "that readers are already performing at the human level as long as relevant\n",
      "passages are provided. The system is also shown to be more effective when the\n",
      "model is induced to give explanations before answering a question. Code is\n",
      "available at \\url{https://github.com/neuralmind-ai/visconde}.\n",
      "________________________________________________________________________________\n",
      "Iterative Multi-document Neural Attention for Multiple Answer Prediction\n",
      "\n",
      "['cs.CL']\n",
      "People have information needs of varying complexity, which can be solved by\n",
      "an intelligent agent able to answer questions formulated in a proper way,\n",
      "eventually considering user context and preferences. In a scenario in which the\n",
      "user profile can be considered as a question, intelligent agents able to answer\n",
      "questions can be used to find the most relevant answers for a given user. In\n",
      "this work we propose a novel model based on Artificial Neural Networks to\n",
      "answer questions with multiple answers by exploiting multiple facts retrieved\n",
      "from a knowledge base. The model is evaluated on the factoid Question Answering\n",
      "and top-n recommendation tasks of the bAbI Movie Dialog dataset. After\n",
      "assessing the performance of the model on both tasks, we try to define the\n",
      "long-term goal of a conversational recommender system able to interact using\n",
      "natural language and to support users in their information seeking processes in\n",
      "a personalized way.\n",
      "________________________________________________________________________________\n",
      "Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata\n",
      "\n",
      "['cs.HC', 'cs.AI']\n",
      "Data is central to the development and evaluation of machine learning (ML)\n",
      "models. However, the use of problematic or inappropriate datasets can result in\n",
      "harms when the resulting models are deployed. To encourage responsible AI\n",
      "practice through more deliberate reflection on datasets and transparency around\n",
      "the processes by which they are created, researchers and practitioners have\n",
      "begun to advocate for increased data documentation and have proposed several\n",
      "data documentation frameworks. However, there is little research on whether\n",
      "these data documentation frameworks meet the needs of ML practitioners, who\n",
      "both create and consume datasets. To address this gap, we set out to understand\n",
      "ML practitioners' data documentation perceptions, needs, challenges, and\n",
      "desiderata, with the goal of deriving design requirements that can inform\n",
      "future data documentation frameworks. We conducted a series of semi-structured\n",
      "interviews with 14 ML practitioners at a single large, international technology\n",
      "company. We had them answer a list of questions taken from datasheets for\n",
      "datasets (Gebru, 2021). Our findings show that current approaches to data\n",
      "documentation are largely ad hoc and myopic in nature. Participants expressed\n",
      "needs for data documentation frameworks to be adaptable to their contexts,\n",
      "integrated into their existing tools and workflows, and automated wherever\n",
      "possible. Despite the fact that data documentation frameworks are often\n",
      "motivated from the perspective of responsible AI, participants did not make the\n",
      "connection between the questions that they were asked to answer and their\n",
      "responsible AI implications. In addition, participants often had difficulties\n",
      "prioritizing the needs of dataset consumers and providing information that\n",
      "someone unfamiliar with their datasets might need to know. Based on these\n",
      "findings, we derive seven design requirements for future data documentation\n",
      "frameworks.\n",
      "________________________________________________________________________________\n",
      "Evaluating a Methodology for Increasing AI Transparency: A Case Study\n",
      "\n",
      "['cs.CY', 'cs.AI']\n",
      "In reaction to growing concerns about the potential harms of artificial\n",
      "intelligence (AI), societies have begun to demand more transparency about how\n",
      "AI models and systems are created and used. To address these concerns, several\n",
      "efforts have proposed documentation templates containing questions to be\n",
      "answered by model developers. These templates provide a useful starting point,\n",
      "but no single template can cover the needs of diverse documentation consumers.\n",
      "It is possible in principle, however, to create a repeatable methodology to\n",
      "generate truly useful documentation. Richards et al. [25] proposed such a\n",
      "methodology for identifying specific documentation needs and creating templates\n",
      "to address those needs. Although this is a promising proposal, it has not been\n",
      "evaluated.\n",
      "  This paper presents the first evaluation of this user-centered methodology in\n",
      "practice, reporting on the experiences of a team in the domain of AI for\n",
      "healthcare that adopted it to increase transparency for several AI models. The\n",
      "methodology was found to be usable by developers not trained in user-centered\n",
      "techniques, guiding them to creating a documentation template that addressed\n",
      "the specific needs of their consumers while still being reusable across\n",
      "different models and use cases. Analysis of the benefits and costs of this\n",
      "methodology are reviewed and suggestions for further improvement in both the\n",
      "methodology and supporting tools are summarized.\n",
      "________________________________________________________________________________\n",
      "GenAIPABench: A Benchmark for Generative AI-based Privacy Assistants\n",
      "\n",
      "['cs.CR', 'cs.CY']\n",
      "Privacy policies of websites are often lengthy and intricate. Privacy\n",
      "assistants assist in simplifying policies and making them more accessible and\n",
      "user friendly. The emergence of generative AI (genAI) offers new opportunities\n",
      "to build privacy assistants that can answer users questions about privacy\n",
      "policies. However, genAIs reliability is a concern due to its potential for\n",
      "producing inaccurate information. This study introduces GenAIPABench, a\n",
      "benchmark for evaluating Generative AI-based Privacy Assistants (GenAIPAs).\n",
      "GenAIPABench includes: 1) A set of questions about privacy policies and data\n",
      "protection regulations, with annotated answers for various organizations and\n",
      "regulations; 2) Metrics to assess the accuracy, relevance, and consistency of\n",
      "responses; and 3) A tool for generating prompts to introduce privacy documents\n",
      "and varied privacy questions to test system robustness. We evaluated three\n",
      "leading genAI systems ChatGPT-4, Bard, and Bing AI using GenAIPABench to gauge\n",
      "their effectiveness as GenAIPAs. Our results demonstrate significant promise in\n",
      "genAI capabilities in the privacy domain while also highlighting challenges in\n",
      "managing complex queries, ensuring consistency, and verifying source accuracy.\n",
      "________________________________________________________________________________\n",
      "InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction\n",
      "\n",
      "['cs.CL']\n",
      "Learning template based information extraction from documents is a crucial\n",
      "yet difficult task. Prior template-based IE approaches assume foreknowledge of\n",
      "the domain templates; however, real-world IE do not have pre-defined schemas\n",
      "and it is a figure-out-as you go phenomena. To quickly bootstrap templates in a\n",
      "real-world setting, we need to induce template slots from documents with zero\n",
      "or minimal supervision. Since the purpose of question answering intersect with\n",
      "the goal of information extraction, we use automatic question generation to\n",
      "induce template slots from the documents and investigate how a tiny amount of a\n",
      "proxy human-supervision on-the-fly (termed as InteractiveIE) can further boost\n",
      "the performance. Extensive experiments on biomedical and legal documents, where\n",
      "obtaining training data is expensive, reveal encouraging trends of performance\n",
      "improvement using InteractiveIE over AI-only baseline.\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for r in client.results(search):\n",
    "  print(r.title)\n",
    "  print(\"\")\n",
    "  print(r.categories)\n",
    "  print(r.summary)\n",
    "  print(\"_\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = next(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../papers/2204.08387v3.LayoutLMv3__Pre_training_for_Document_AI_with_Unified_Text_and_Image_Masking.pdf'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.download_pdf(dirpath=\"../papers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperlight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
