{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 14:40:50.351 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "\n",
    "from src.process import process_arxiv_paper_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_url = \"https://arxiv.org/abs/2204.08387\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 14:40:50.462 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/david/projects/paperlight/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-02-18 14:40:50.463 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring overlapping sections. Closing previous section 'Introduction'.\n",
      "Warning: Ignoring overlapping sections. Closing previous section 'LayoutLMv3'.\n",
      "Warning: Ignoring overlapping sections. Closing previous section 'Experiments'.\n",
      "Warning: Ignoring overlapping sections. Closing previous section 'Related Work'.\n",
      "Warning: Ignoring overlapping sections. Closing previous section 'Conclusion and Future Work'.\n",
      "Warning: Ignoring overlapping sections. Closing previous section 'Acknowledgement'.\n"
     ]
    }
   ],
   "source": [
    "tex_content, _ = process_arxiv_paper_from_url(paper_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section, content in tex_content.items():\n",
    "    print(section)\n",
    "    print(\"-\"*20)\n",
    "    print(content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=text, metadata={\"section\": section})\n",
    "    for section, text in tex_content.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2024, chunk_overlap=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate similarity search\n",
    "question = \"is there an email i can ask for help\"\n",
    "simmilar_docs = vectorstore.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values_dict(list_):\n",
    "    return list(dict.fromkeys(list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_section_metadata(docs):\n",
    "    sections = unique_values_dict([doc.metadata.get(\"section\", \"Unknown\") for doc in docs])\n",
    "    return \"Information was retrieved from following sections: \" + \", \".join(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = load_prompt(\"prompts/pb.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=(lambda x: format_docs(x[\"raw_context\"])),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\n",
    "        \"raw_context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ").assign(\n",
    "    answer=rag_chain_from_docs,\n",
    "    sources=(lambda x: format_section_metadata(x[\"raw_context\"])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_source.invoke(\"What is this paper about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in rag_chain_with_source.stream(\"What is this paper about?\"):\n",
    "    if chunk.get(\"sources\"):\n",
    "        source = chunk.get(\"sources\")\n",
    "    if chunk.get(\"answer\"):\n",
    "        print(chunk.get(\"answer\"), end=\"\", flush=True)\n",
    "print(\"\\n\" + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.qa_chain import get_qa_chain, _tex_to_splits\n",
    "from src.display import streamify_qa_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = get_qa_chain(tex_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_qa_response(chain, question):\n",
    "    \"\"\"\n",
    "    Streamify an LLM response.\n",
    "\n",
    "    Args:\n",
    "    - llm_response: str: The LLM response\n",
    "\n",
    "    Returns:\n",
    "    - str: The streamified LLM response\n",
    "    \"\"\"\n",
    "    for chunk in chain.stream(question):\n",
    "        if chunk.get(\"sources\"):\n",
    "            source = chunk.get(\"sources\")\n",
    "        if chunk.get(\"answer\"):\n",
    "            print(chunk.get(\"answer\"), end=\"\", flush=True)\n",
    "    print(\"\\n\" + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper is about LayoutLMv3, a multimodal Transformer model designed for Document AI tasks that uses unified text and image masking pre-training objectives to learn multimodal representations. LayoutLMv3 does not rely on pre-trained CNN or Faster R-CNN backbones, achieving generality and superiority for both text-centric and image-centric Document AI tasks. The paper also discusses the effect of linear image embeddings and different pre-training objectives on the model's performance.\n",
      "\n",
      "Information was retrieved from following sections: Conclusion and Future Work, Experiments, Introduction"
     ]
    }
   ],
   "source": [
    "for chunk in streamify_qa_response(qa_chain, \"What is this paper about?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"What is this paper about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in qa_chain.stream(\"What is this paper about?\"):\n",
    "    if chunk.get(\"sources\"):\n",
    "        source = chunk.get(\"sources\")\n",
    "    if chunk.get(\"answer\"):\n",
    "        print(chunk.get(\"answer\"), end=\"\", flush=True)\n",
    "print(\"\\n\" + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in qa_chain.stream(\"What is this paper about?\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
