{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "        \"\"\"You are a skilled researcher and very good tutor, skilled in explaining complex AI topics and concepts. You will be provided with scientific paper abstract ,that you will summarize and explain to a high-school student.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": r\"\"\"Self-supervised pre-training techniques have achieved remarkable progress in Document AI. Most multimodal pre-trained models use a masked language modeling objective to learn bidirectional representations on the text modality, but they differ in pre-training objectives for the image modality. This discrepancy adds difficulty to multimodal representation learning. In this paper, we propose \\textbf{LayoutLMv3} to pre-train multimodal Transformers for Document AI with unified text and image masking. Additionally, LayoutLMv3 is pre-trained with a word-patch alignment objective to learn cross-modal alignment by predicting whether the corresponding image patch of a text word is masked. The simple unified architecture and training objectives make LayoutLMv3 a general-purpose pre-trained model for both text-centric and image-centric Document AI tasks. Experimental results show that LayoutLMv3 achieves state-of-the-art performance not only in text-centric tasks, including form understanding, receipt understanding, and document visual question answering, but also in image-centric tasks such as document image classification and document layout analysis. The code and models are publicly available at \\url{this https URL}.\"\"\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8qJyexjmPSrXEH0DXHFGbgRGNgjsf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Researchers have made significant progress in using self-supervised pre-training techniques for Document AI. These techniques involve training models to understand documents by learning representations from both text and image data. However, previous models have focused on different objectives for pre-training on text and image, which has made it difficult to combine these representations effectively.\\n\\nIn this paper, the authors propose a new model called LayoutLMv3. This model aims to pre-train multimodal Transformers, which are able to process both text and image data, for Document AI tasks. LayoutLMv3 is designed with a unified approach, where both text and image are trained using the same masked language modeling objective. This means that the model is trained to predict missing words in text and missing patches in images.\\n\\nTo further enhance the model's ability to align text and image data, LayoutLMv3 is also trained with a word-patch alignment objective. This objective involves predicting whether an image patch corresponds to a masked word in the text data. By doing this, the model learns how to associate specific image regions with particular words in the text.\\n\\nThe authors demonstrate that LayoutLMv3 outperforms other pre-trained models in various Document AI tasks. These tasks include understanding forms, receipts, and answering visual questions about documents. Additionally, LayoutLMv3 also achieves excellent results in image-centric tasks such as document image classification and document layout analysis.\\n\\nThe code and models for LayoutLMv3 are available to the public, allowing other researchers and developers to utilize and build upon this model for their own Document AI applications.\", role='assistant', function_call=None, tool_calls=None))], created=1707480540, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=312, prompt_tokens=272, total_tokens=584))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researchers have made significant progress in using self-supervised pre-training techniques for Document AI. These techniques involve training models to understand documents by learning representations from both text and image data. However, previous models have focused on different objectives for pre-training on text and image, which has made it difficult to combine these representations effectively.\n",
      "\n",
      "In this paper, the authors propose a new model called LayoutLMv3. This model aims to pre-train multimodal Transformers, which are able to process both text and image data, for Document AI tasks. LayoutLMv3 is designed with a unified approach, where both text and image are trained using the same masked language modeling objective. This means that the model is trained to predict missing words in text and missing patches in images.\n",
      "\n",
      "To further enhance the model's ability to align text and image data, LayoutLMv3 is also trained with a word-patch alignment objective. This objective involves predicting whether an image patch corresponds to a masked word in the text data. By doing this, the model learns how to associate specific image regions with particular words in the text.\n",
      "\n",
      "The authors demonstrate that LayoutLMv3 outperforms other pre-trained models in various Document AI tasks. These tasks include understanding forms, receipts, and answering visual questions about documents. Additionally, LayoutLMv3 also achieves excellent results in image-centric tasks such as document image classification and document layout analysis.\n",
      "\n",
      "The code and models for LayoutLMv3 are available to the public, allowing other researchers and developers to utilize and build upon this model for their own Document AI applications.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8qJm2X5ZRkCSGNpAh1K6OSSAOV8L4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In the realm of code, a tale I will weave,\\nOf a loop so enchanting, yet hard to believe.\\nIn a dance of reflection, a pattern so serene,\\nRecursion, they call it, a programmer's dream.\\n\\nImagine a function, a wizard so sly,\\nWhose power lies in calling itself, Oh my!\\nLike a mirror within a mirror, it repeats without end,\\nWith each iteration, new realms it transcends.\\n\\nA problem, it's said, can be broken down small,\\nAnd recursion lends a hand, answering the call.\\nInto smaller pieces, the task it divides,\\nSolving them all, until satisfaction resides.\\n\\nLike Fibonacci's numbers, a sequence divine,\\nWhere the next is the sum of the two behind.\\nRecursion unwinds, like a spiral so grand,\\nFetching answers, by the magician's command.\\n\\nThrough labyrinths and mazes, recursion explores,\\nAn adventurer bold, who never ignores.\\nBacktracking gracefully, tracing its path,\\nSolving problems transparent, like a lover's laugh.\\n\\nBut beware, O programmer, with this power to create,\\nFor a runaway recursion can seal your fate.\\nWith no end in sight, it consumes without cease,\\nAn infinite loop, a daunting release.\\n\\nSo handle with caution, this spellbinding force,\\nLike a double-edged sword, of course.\\nWith careful design, and a stopping condition,\\nRecursion brings elegance, with precision.\\n\\nIn the tapestry of code, recursion weaves,\\nA symphony of logic, each time it conceives.\\nSo embrace this concept, with wisdom and care,\\nAnd let recursion guide you, through the programming lair.\", role='assistant', function_call=None, tool_calls=None))], created=1707479758, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=331, prompt_tokens=39, total_tokens=370))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperlight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
